{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e16f42",
   "metadata": {},
   "source": [
    "# A look at some of the readability score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ab384",
   "metadata": {},
   "source": [
    "<A HREF=\"https://en.wikipedia.org/wiki/Readability\">Wikipedia - Readability</A><BR>\n",
    "<A HREF=\"https://www.geeksforgeeks.org/readability-index-pythonnlp/\">GeeksforGeeks Readability - Index in Python</A><BR>\n",
    "<A HREF=\"https://pypi.org/project/readability/\">Readability python package</A><BR>\n",
    "    <A HREF=\"https://pypi.org/project/textstat/\">Textstat python package</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2cad4362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/muddy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/muddy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "import en_core_web_md\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import readability\n",
    "import pprint # pretty print for easy printing of ordered dictionary\n",
    "# import spacy # Needed for GeeksforGeeks code which is a mess\n",
    "from textstat.textstat import textstatistics\n",
    "import spacy\n",
    "spacy.load('en_core_web_md')\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download ('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b92c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>depth</th>\n",
       "      <th>TBsubjectivity</th>\n",
       "      <th>TBpolarity</th>\n",
       "      <th>words_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.06240</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.064416</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.130252</td>\n",
       "      <td>47</td>\n",
       "      <td>1459</td>\n",
       "      <td>620</td>\n",
       "      <td>7.276596</td>\n",
       "      <td>0.406976</td>\n",
       "      <td>0.135880</td>\n",
       "      <td>31.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.064398</td>\n",
       "      <td>0.064471</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.048739</td>\n",
       "      <td>0.159664</td>\n",
       "      <td>217</td>\n",
       "      <td>5856</td>\n",
       "      <td>939</td>\n",
       "      <td>5.986175</td>\n",
       "      <td>0.445383</td>\n",
       "      <td>0.167408</td>\n",
       "      <td>26.986175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date source       ADJ       ADP      ADV       AUX     CCONJ  \\\n",
       "0 2008-06-04    nyt  0.064458  0.065088  0.06240  0.064962  0.064416   \n",
       "1 2008-06-04    oba  0.064649  0.064670  0.06444  0.064398  0.064471   \n",
       "\n",
       "        DET      INTJ      NOUN  ...   sadness  surprise     trust  num_sents  \\\n",
       "0  0.063408  0.055598  0.064920  ...  0.075630  0.046218  0.130252         47   \n",
       "1  0.064638  0.054967  0.064503  ...  0.042017  0.048739  0.159664        217   \n",
       "\n",
       "   num_words  num_unique_words     depth  TBsubjectivity TBpolarity  \\\n",
       "0       1459               620  7.276596        0.406976   0.135880   \n",
       "1       5856               939  5.986175        0.445383   0.167408   \n",
       "\n",
       "   words_per_sentence  \n",
       "0           31.042553  \n",
       "1           26.986175  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_data = pd.read_csv('tidy_data.csv')\n",
    "tidy_data['date'] = pd.to_datetime(tidy_data['date'], format='%Y-%m-%d')\n",
    "tidy_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c3ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-07-28</td>\n",
       "      <td>oba</td>\n",
       "      <td>On behalf of the great state of Illinois, cros...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-07-28</td>\n",
       "      <td>oba</td>\n",
       "      <td>Tonight is a particular honor for me because, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date source                                           sentence  depth\n",
       "0 2004-07-28    oba  On behalf of the great state of Illinois, cros...      8\n",
       "1 2004-07-28    oba  Tonight is a particular honor for me because, ...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.read_csv('sentence_depth.csv')\n",
    "sentences['date'] = pd.to_datetime(sentences['date'], format='%Y-%m-%d')\n",
    "sentences.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0daaa62",
   "metadata": {},
   "source": [
    "### First, using the readability package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text should be encoded with UTF-8, one sentence per line, tokens space-separated.\n",
    "results = readability.getmeasures(sentences['sentence'][0], lang='en')\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ffe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(results['readability grades'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf8a94",
   "metadata": {},
   "source": [
    "### I'm gonna try some stuff below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59dc0d",
   "metadata": {},
   "source": [
    "<A HREF=\"https://computingeverywhere.soc.northwestern.edu/wp-content/uploads/2017/07/Text-Analysis-with-NLTK-Cheatsheet.pdf\">Northwestern NLTK cheat sheet</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fc6fff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    On behalf of the great state of Illinois, cros...\n",
       "1    Tonight is a particular honor for me because, ...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['sentence'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "216a7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## HELPER FUNCTIONS ########################\n",
    "def words_per_sentence(sentence):\n",
    "    '''returns: integer number of words in a sentence'''\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return(len(tokens))\n",
    "\n",
    "def chars_per_word(word):\n",
    "    '''returns: integer number of characters in a word'''\n",
    "    return(len(word))\n",
    "\n",
    "def string_to_list(sentence):\n",
    "    '''converts a string/sentence to a list of words'''\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return(tokenizer.tokenize(sentence))\n",
    "\n",
    "def chars_per_word_sentence(sentence):\n",
    "    '''input: string of a sentence\n",
    "       returns: list of number of characters in a sentence'''\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    char_len_list = [chars_per_word(word) for word in tokens]\n",
    "    return(char_len_list)\n",
    "\n",
    "def text_to_sentence(text):\n",
    "    '''uses spacy nlp object to break up sentences\n",
    "       input: pandas series of strings\n",
    "       returns: list of sentence strings'''\n",
    "    doc = nlp(' '.join(text.tolist()))\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    return([str(sent) for sent in doc.sents])\n",
    "\n",
    "def text_to_wordlist(text):\n",
    "    '''input: string or pandas series of text\n",
    "       returns: list of all words'''\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    return(' '.join(text).split())\n",
    "\n",
    "def syllable_count(word):\n",
    "    '''counts number of syllables in a word'''\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def count_total_words(text):\n",
    "    '''count total number of words in a text\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer'''\n",
    "    if isinstance(text, list):\n",
    "        list_of_sentence = text\n",
    "    elif isinstance(text, str):\n",
    "        list_of_sentence = [text]\n",
    "    elif isinstance(text, pd.Series):\n",
    "        list_of_sentence = text_to_sentence(text)\n",
    "    else:\n",
    "        print('count_total_words: Error: not a string or pandas series object.')\n",
    "    list_of_word_count = [words_per_sentence(str(sentence)) for sentence in list_of_sentence]\n",
    "    return(np.sum(list_of_word_count))\n",
    "\n",
    "def count_total_sentences(text):\n",
    "    '''count total number of sentences in a text\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer'''\n",
    "    if isinstance(text, pd.Series):\n",
    "        text = ' '.join(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    return(len(sentences))\n",
    "\n",
    "# Count Syllables\n",
    "# https://datascience.stackexchange.com/questions/23376/how-to-get-the-number-of-syllables-in-a-word\n",
    "def syllables(word):\n",
    "    '''backup syllable counter if word not in NLTK-CMU dictionary'''\n",
    "    #referred from stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    try:\n",
    "        if word[0] in vowels:\n",
    "            count +=1\n",
    "    except:\n",
    "        count += 0\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "d = cmudict.dict()\n",
    "def nsyl(word):\n",
    "    '''input: string - word\n",
    "       returns: integer count of syllables in word'''\n",
    "    try:\n",
    "        # needs the [0] otherwise words like 'of' returns [1,1]\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "    except KeyError:\n",
    "        #if word not found in cmudict\n",
    "        return syllables(word)\n",
    "\n",
    "def count_total_syllables(text):\n",
    "    '''count total number of sentences in a text\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer count'''\n",
    "    if isinstance(text, str):\n",
    "        list_of_sentence = [text]\n",
    "    elif isinstance(text, pd.Series):\n",
    "        list_of_sentence = text_to_sentence(text)\n",
    "    else:\n",
    "        print('count_total_syllables: Error: not a string or pandas series object.')\n",
    "    list_of_words = text_to_wordlist(list_of_sentence)\n",
    "    syllable_list = [nsyl(word) for word in list_of_words]\n",
    "    return(np.sum(syllable_list))\n",
    "\n",
    "def count_of_letters(text):\n",
    "    '''count total number of letters or digits in a text\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer count'''\n",
    "    if isinstance(text, pd.Series):\n",
    "        text = ' '.join(text)\n",
    "    # Replace punctuations with an empty string.\n",
    "    str1 = re.sub(r\"[^\\w\\s]|_\", \"\", text)\n",
    "    no_spaces = str1.replace(\" \", \"\")\n",
    "    return(len(no_spaces))\n",
    "\n",
    "\n",
    "def difficult_words_list(list1):\n",
    "    '''returns difference of list with easy_word list for Dale-Chall\n",
    "       input: two lists of strings/words\n",
    "       returns: list of unique words in both lists'''\n",
    "    if isinstance(list1, pd.Series):\n",
    "        list1 = ' '.join(text)\n",
    "    if isinstance(list1, list):\n",
    "        list1 = list1[0]\n",
    "    try:\n",
    "        easy_words_file = open('./word_lists/DaleChallEasyWordList.txt', 'r')\n",
    "        easy_words = easy_words_file.read().split('\\n')\n",
    "    except E:\n",
    "        print(\"Error reading easy words file\", E)\n",
    "    easy_words_file.close()\n",
    "    easy_words = [word.lower() for word in easy_words]\n",
    "    easy_words = set(easy_words)\n",
    "    diff = [word.lower() for word in list1.split() if word.lower() not in easy_words]\n",
    "    return(diff)\n",
    "\n",
    "def dc_difficult_word_count(text):\n",
    "    '''Count of difficult words - those not in Dale-Chall Easy Word List\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer count of difficult words in text'''\n",
    "    list_of_dc_difficult = difficult_words_list(text)\n",
    "    return(len(list_of_dc_difficult))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def gf_complex_word_count(text):\n",
    "    '''Count of complex - >= 3 syllables with caveats\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer count of complex words in text'''\n",
    "    if isinstance(text, pd.Series):\n",
    "        text = ' '.join(text)\n",
    "    if isinstance(text, list):\n",
    "        text = str(text[0])\n",
    "    text = [word.lower() for word in text.split()]\n",
    "    lemma = [lemmatizer.lemmatize(word) for word in text]\n",
    "    stem = [re.sub(\"(?:ing|ed|es|ly)$\",\"\",word) for word in text]\n",
    "    syllable_list = [nsyl(word) for word in stem]\n",
    "    complex_count = sum(x > 2 for x in syllable_list)\n",
    "    return(complex_count)\n",
    "\n",
    "def smog_poly_count(text):\n",
    "    '''counts number of words with 3 or more syllables\n",
    "       input: str or pandas.core.series.Series of text\n",
    "       returns: integer count of polysyllabic words in text'''\n",
    "    if isinstance(text, pd.Series):\n",
    "        text = ' '.join(text)\n",
    "    if isinstance(text, list):\n",
    "        text = str(text[0])\n",
    "    text = [word.lower() for word in text.split()]\n",
    "    syllable_list = [nsyl(word) for word in text]\n",
    "    poly_count = sum(x > 2 for x in syllable_list)\n",
    "    return(poly_count)\n",
    "\n",
    "\n",
    "######################## READABILITY SCORES ########################\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Automated_readability_index\n",
    "# 4.71(chars/word) + 0.5(words/sentence) - 21.43\n",
    "def ari(text):\n",
    "    '''input: string of sentence\n",
    "       returns: float ari score'''\n",
    "    character_count = count_of_letters(text)\n",
    "    word_count = count_total_words(text)\n",
    "    sentence_count = count_total_sentences(text)\n",
    "    ari = 4.71*(character_count/word_count) + 0.5*(word_count/sentence_count) - 21.43\n",
    "    return(ari)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
    "# Fleschâ€“Kincaid grade level\n",
    "# 0.39(total words/total sentences) + 11.8(total syllables/total words) - 15.59\n",
    "def flesch_kincaid(text):\n",
    "    '''input: string or pandas series of text, multiple sentences\n",
    "       returns: float - flesh kincaid grade level score'''\n",
    "    num_total_words = count_total_words(text)\n",
    "    num_total_sentences = count_total_sentences(text)\n",
    "    num_total_syllables = count_total_syllables(text)\n",
    "    fkgl = 0.39*(num_total_words/num_total_sentences) + 11.8*(num_total_syllables/num_total_words) - 15.59\n",
    "    return(fkgl)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
    "# 0.0588(average number of letters per 100 words) - 0.296(average number of sentences per 100 words) - 15.8\n",
    "def coleman_liau(text):\n",
    "    '''input: string or pandas series of text, multiple sentences\n",
    "       returns: float - Coleman-Liau index'''\n",
    "    character_count = count_of_letters(text)\n",
    "    word_count = count_total_words(text)\n",
    "    sentence_count = count_total_sentences(text)\n",
    "    l = character_count/word_count*100\n",
    "    s = sentence_count/word_count*100\n",
    "    cl = 0.0588*l - 0.296*s - 15.8\n",
    "    return(cl)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Dale%E2%80%93Chall_readability_formula\n",
    "# 0.1579(100*difficult words/words) + 0.496(words/sentences)\n",
    "def dale_chall(text):\n",
    "    '''input: string or pandas series of text, multiple sentences\n",
    "       returns: float - Dale-Chall readability score'''\n",
    "    difficult_words = dc_difficult_word_count(text)\n",
    "    word_count = count_total_words(text)\n",
    "    sentence_count = count_total_sentences(text)\n",
    "    dc = 0.1579*(100*difficult_words/word_count) + 0.496*(word_count/sentence_count)\n",
    "    return(dc)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Gunning_fog_index\n",
    "# 0.4[(words/sentence) + 100(complex words/words)]\n",
    "def gunning_fog(text):\n",
    "    '''input: string or pandas series of text, multiple sentences\n",
    "       returns: float - Gunning Fog index readability score'''\n",
    "    complex_words = gf_complex_word_count(text)\n",
    "    word_count = count_total_words(text)\n",
    "    sentence_count = count_total_sentences(text)\n",
    "    gf = 0.4*((word_count/sentence_count) + 100*(complex_words/word_count))\n",
    "    return(gf)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/SMOG\n",
    "# 1.043*sqrt(30*number polysylables/number sentences)+3.1291\n",
    "def smog(text):\n",
    "    '''input: string or pandas series of text, multiple sentences\n",
    "       returns: float - SMOG grade readability score'''\n",
    "    poly_count = smog_poly_count(text)\n",
    "    sentence_count = count_total_sentences(text)\n",
    "    smog_score = 1.043*np.sqrt(30*poly_count/sentence_count) + 3.1291\n",
    "    return(smog_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "19db172b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.521786647896054"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_count = count_of_letters(text)\n",
    "syl_count = count_total_syllables(text)\n",
    "word_count = count_total_words(text)\n",
    "char_per_word = char_count/word_count\n",
    "syl_per_word = syl_count/word_count\n",
    "sent_count = count_total_sentences(text)\n",
    "word_per_sent = word_count/sent_count\n",
    "\n",
    "dc_word_count = dc_difficult_word_count(text)\n",
    "gf_word_count = gf_complex_word_count(text)\n",
    "ploy_word_count = smog_poly_count(text)\n",
    "\n",
    "ari(text)\n",
    "flesch_kincaid(text)\n",
    "coleman_liau(text)\n",
    "dale_chall(text)\n",
    "gunning_fog(text)\n",
    "smog(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a543fd",
   "metadata": {},
   "source": [
    "### Load up the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "edb8b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon, everybody. One year ago this m...</td>\n",
       "      <td>./speeches/2014-07-01-Immigration.txt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>oba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, everybody. I want to take just a...</td>\n",
       "      <td>./speeches/2009-12-25-UnderwearBomber.txt</td>\n",
       "      <td>2009-12-25</td>\n",
       "      <td>oba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello, Chicago.\\n\\nIf there is anyone out ther...</td>\n",
       "      <td>./speeches/2008-11-05-ObamaElected.txt</td>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>oba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Good afternoon, everybody. One year ago this m...   \n",
       "1  Good morning, everybody. I want to take just a...   \n",
       "2  Hello, Chicago.\\n\\nIf there is anyone out ther...   \n",
       "\n",
       "                                    filepath       date source  \n",
       "0      ./speeches/2014-07-01-Immigration.txt 2014-07-01    oba  \n",
       "1  ./speeches/2009-12-25-UnderwearBomber.txt 2009-12-25    oba  \n",
       "2     ./speeches/2008-11-05-ObamaElected.txt 2008-11-05    oba  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the files\n",
    "paths = ['./speeches/', './NYTimes/', './WSJ/'] \n",
    "list_of_files = []\n",
    "\n",
    "dates = pd.read_csv('dateSpeeches.csv')\n",
    "for path in paths:\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                list_of_files.append(os.path.join(root,file))\n",
    "\n",
    "speeches = []\n",
    "for file in list_of_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        #print(file)\n",
    "        text = f.read()\n",
    "    f.close()\n",
    "    speeches.append([text, file])\n",
    "\n",
    "#clean out goofy unicode  space characters \n",
    "speeches = [(unicodedata.normalize(\"NFKD\", speech[0]), speech[1]) for speech in speeches if len(speech)>0 ]\n",
    "\n",
    "# remove [stuff] in between square brackets\n",
    "def remove_bracket(text):\n",
    "    return re.sub('(\\[[^w]*\\]\\s)', '',text)\n",
    "speeches = [(remove_bracket(speech[0]), speech[1]) for speech in speeches]\n",
    "\n",
    "def get_source(text):\n",
    "    regex = \"[^./][a-zA-Z]+[^/]\"\n",
    "    string = re.findall(regex, str(text))[0]\n",
    "    if string == 'speeches': string = 'oba'\n",
    "    if string == 'NYTimes': string = 'nyt'\n",
    "    return string.lower()\n",
    "\n",
    "def get_date(text):\n",
    "    regex = \"([0-9]+[\\-][0-9]+[\\-][0-9]+)\"\n",
    "    return re.findall(regex, str(text))[0]\n",
    "\n",
    "def get_filename(text):\n",
    "    regex = \"[-]([a-zA-Z]+)\"\n",
    "    return re.findall(regex, str(text))[0]\n",
    "\n",
    "cols = ['text', 'filepath']\n",
    "text_df = pd.DataFrame(speeches, columns=cols)\n",
    "text_df['date'] = text_df['filepath'].apply(get_date)\n",
    "text_df['date'] = pd.to_datetime(text_df['date'], format='%Y-%m-%d')\n",
    "text_df['source'] = text_df['filepath'].apply(get_source)\n",
    "\n",
    "text_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "6f52b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['char_count'] = text_df['text'].apply(count_of_letters)\n",
    "text_df['syl_count'] = text_df['text'].apply(count_total_syllables)\n",
    "text_df['word_count'] = text_df['text'].apply(count_total_words)\n",
    "text_df['char_per_word'] = text_df['char_count']/text_df['word_count']#\n",
    "text_df['syl_per_word'] = text_df['syl_count']/text_df['word_count']#\n",
    "text_df['sent_count'] = text_df['text'].apply(count_total_sentences)\n",
    "text_df['word_per_sent'] = text_df['word_count']/text_df['sent_count']#\n",
    "\n",
    "text_df['dc_word_count'] = text_df['text'].apply(dc_difficult_word_count)\n",
    "text_df['gf_word_count'] = text_df['text'].apply(gf_complex_word_count)\n",
    "text_df['poly_word_count'] = text_df['text'].apply(smog_poly_count)\n",
    "\n",
    "text_df['dc_word_perc'] = text_df['dc_word_count']/text_df['word_count']#\n",
    "text_df['gf_word_perc'] = text_df['gf_word_count']/text_df['word_count']#\n",
    "text_df['poly_word_perc'] = text_df['poly_word_count']/text_df['word_count']#\n",
    "\n",
    "text_df['ari'] = text_df['text'].apply(ari)\n",
    "text_df['flesch_kincaid'] = text_df['text'].apply(flesch_kincaid)\n",
    "text_df['coleman_liau'] = text_df['text'].apply(coleman_liau)\n",
    "text_df['dale_chall'] = text_df['text'].apply(dale_chall)\n",
    "text_df['gunning_fog'] = text_df['text'].apply(gunning_fog)\n",
    "text_df['smog'] = text_df['text'].apply(smog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "9efb6f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "      <th>syl_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_per_word</th>\n",
       "      <th>syl_per_word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>...</th>\n",
       "      <th>poly_word_count</th>\n",
       "      <th>dc_word_perc</th>\n",
       "      <th>gf_word_perc</th>\n",
       "      <th>poly_word_perc</th>\n",
       "      <th>ari</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon, everybody. One year ago this m...</td>\n",
       "      <td>./speeches/2014-07-01-Immigration.txt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>oba</td>\n",
       "      <td>9131</td>\n",
       "      <td>3044</td>\n",
       "      <td>2057</td>\n",
       "      <td>4.438989</td>\n",
       "      <td>1.479825</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>248</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.120564</td>\n",
       "      <td>8.660673</td>\n",
       "      <td>9.034703</td>\n",
       "      <td>8.689587</td>\n",
       "      <td>13.976300</td>\n",
       "      <td>11.682841</td>\n",
       "      <td>11.629938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, everybody. I want to take just a...</td>\n",
       "      <td>./speeches/2009-12-25-UnderwearBomber.txt</td>\n",
       "      <td>2009-12-25</td>\n",
       "      <td>oba</td>\n",
       "      <td>5269</td>\n",
       "      <td>1782</td>\n",
       "      <td>1106</td>\n",
       "      <td>4.764014</td>\n",
       "      <td>1.611212</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.331826</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.169982</td>\n",
       "      <td>11.442470</td>\n",
       "      <td>11.560787</td>\n",
       "      <td>10.793960</td>\n",
       "      <td>15.590029</td>\n",
       "      <td>14.206121</td>\n",
       "      <td>13.888447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello, Chicago.\\n\\nIf there is anyone out ther...</td>\n",
       "      <td>./speeches/2008-11-05-ObamaElected.txt</td>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>oba</td>\n",
       "      <td>8752</td>\n",
       "      <td>2896</td>\n",
       "      <td>2093</td>\n",
       "      <td>4.181558</td>\n",
       "      <td>1.383660</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.270903</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.089823</td>\n",
       "      <td>9.166178</td>\n",
       "      <td>9.239998</td>\n",
       "      <td>7.429890</td>\n",
       "      <td>15.091392</td>\n",
       "      <td>11.912424</td>\n",
       "      <td>11.123544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon, everybody. As a candidate for ...</td>\n",
       "      <td>./speeches/2011-12-16-EndIraqWar.txt</td>\n",
       "      <td>2011-12-16</td>\n",
       "      <td>oba</td>\n",
       "      <td>4416</td>\n",
       "      <td>1519</td>\n",
       "      <td>982</td>\n",
       "      <td>4.496945</td>\n",
       "      <td>1.546843</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>0.340122</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>0.155804</td>\n",
       "      <td>9.378062</td>\n",
       "      <td>10.172161</td>\n",
       "      <td>9.104766</td>\n",
       "      <td>14.920961</td>\n",
       "      <td>13.363875</td>\n",
       "      <td>13.023867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you. Good evening, everybody. Good eveni...</td>\n",
       "      <td>./speeches/2012-04-29-WHCorrespondentsDinner.txt</td>\n",
       "      <td>2012-04-29</td>\n",
       "      <td>oba</td>\n",
       "      <td>5559</td>\n",
       "      <td>1862</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.154709</td>\n",
       "      <td>1.391629</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.305680</td>\n",
       "      <td>0.088191</td>\n",
       "      <td>0.097160</td>\n",
       "      <td>5.572010</td>\n",
       "      <td>6.629226</td>\n",
       "      <td>6.638655</td>\n",
       "      <td>12.200556</td>\n",
       "      <td>9.474320</td>\n",
       "      <td>9.994967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>President Barack Obama, emphasizing U.S. allie...</td>\n",
       "      <td>./WSJ/2014-03-26-NATOBelgium.txt</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>wsj</td>\n",
       "      <td>4810</td>\n",
       "      <td>1627</td>\n",
       "      <td>957</td>\n",
       "      <td>5.026123</td>\n",
       "      <td>1.700104</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.168234</td>\n",
       "      <td>0.185998</td>\n",
       "      <td>14.512272</td>\n",
       "      <td>14.041233</td>\n",
       "      <td>12.547335</td>\n",
       "      <td>19.430847</td>\n",
       "      <td>16.544747</td>\n",
       "      <td>15.333674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>The White House cleared the way for tough new ...</td>\n",
       "      <td>./WSJ/2012-03-31-OilIran.txt</td>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>wsj</td>\n",
       "      <td>2251</td>\n",
       "      <td>765</td>\n",
       "      <td>459</td>\n",
       "      <td>4.904139</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0.466231</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>13.143497</td>\n",
       "      <td>13.027167</td>\n",
       "      <td>11.746580</td>\n",
       "      <td>18.744986</td>\n",
       "      <td>15.454510</td>\n",
       "      <td>14.625780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>President Barack Obama, seeking to restore con...</td>\n",
       "      <td>./WSJ/2014-01-29-StateoftheUnion.txt</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>wsj</td>\n",
       "      <td>5540</td>\n",
       "      <td>1898</td>\n",
       "      <td>1151</td>\n",
       "      <td>4.813206</td>\n",
       "      <td>1.649001</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>0.422242</td>\n",
       "      <td>0.166811</td>\n",
       "      <td>0.183319</td>\n",
       "      <td>13.751069</td>\n",
       "      <td>13.626689</td>\n",
       "      <td>11.318679</td>\n",
       "      <td>19.077976</td>\n",
       "      <td>16.681154</td>\n",
       "      <td>15.364192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>President Barack Obama won re-election Tuesday...</td>\n",
       "      <td>./WSJ/2012-11-07-ObamaWinsRe-election.txt</td>\n",
       "      <td>2012-11-07</td>\n",
       "      <td>wsj</td>\n",
       "      <td>7763</td>\n",
       "      <td>2650</td>\n",
       "      <td>1631</td>\n",
       "      <td>4.759657</td>\n",
       "      <td>1.624770</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>0.404660</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.177805</td>\n",
       "      <td>10.933105</td>\n",
       "      <td>11.339482</td>\n",
       "      <td>10.698614</td>\n",
       "      <td>16.255138</td>\n",
       "      <td>14.209930</td>\n",
       "      <td>13.872383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>The Group of 20 nations is close to an agreeme...</td>\n",
       "      <td>./WSJ/2016-09-05-G20Summit.txt</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>wsj</td>\n",
       "      <td>6169</td>\n",
       "      <td>2052</td>\n",
       "      <td>1258</td>\n",
       "      <td>4.903816</td>\n",
       "      <td>1.631161</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>0.440382</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>14.000305</td>\n",
       "      <td>13.277695</td>\n",
       "      <td>11.834436</td>\n",
       "      <td>19.188291</td>\n",
       "      <td>16.575729</td>\n",
       "      <td>15.521787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Good afternoon, everybody. One year ago this m...   \n",
       "1    Good morning, everybody. I want to take just a...   \n",
       "2    Hello, Chicago.\\n\\nIf there is anyone out ther...   \n",
       "3    Good afternoon, everybody. As a candidate for ...   \n",
       "4    Thank you. Good evening, everybody. Good eveni...   \n",
       "..                                                 ...   \n",
       "298  President Barack Obama, emphasizing U.S. allie...   \n",
       "299  The White House cleared the way for tough new ...   \n",
       "300  President Barack Obama, seeking to restore con...   \n",
       "301  President Barack Obama won re-election Tuesday...   \n",
       "302  The Group of 20 nations is close to an agreeme...   \n",
       "\n",
       "                                             filepath       date source  \\\n",
       "0               ./speeches/2014-07-01-Immigration.txt 2014-07-01    oba   \n",
       "1           ./speeches/2009-12-25-UnderwearBomber.txt 2009-12-25    oba   \n",
       "2              ./speeches/2008-11-05-ObamaElected.txt 2008-11-05    oba   \n",
       "3                ./speeches/2011-12-16-EndIraqWar.txt 2011-12-16    oba   \n",
       "4    ./speeches/2012-04-29-WHCorrespondentsDinner.txt 2012-04-29    oba   \n",
       "..                                                ...        ...    ...   \n",
       "298                  ./WSJ/2014-03-26-NATOBelgium.txt 2014-03-26    wsj   \n",
       "299                      ./WSJ/2012-03-31-OilIran.txt 2012-03-31    wsj   \n",
       "300              ./WSJ/2014-01-29-StateoftheUnion.txt 2014-01-29    wsj   \n",
       "301         ./WSJ/2012-11-07-ObamaWinsRe-election.txt 2012-11-07    wsj   \n",
       "302                    ./WSJ/2016-09-05-G20Summit.txt 2016-09-05    wsj   \n",
       "\n",
       "     char_count  syl_count  word_count  char_per_word  syl_per_word  \\\n",
       "0          9131       3044        2057       4.438989      1.479825   \n",
       "1          5269       1782        1106       4.764014      1.611212   \n",
       "2          8752       2896        2093       4.181558      1.383660   \n",
       "3          4416       1519         982       4.496945      1.546843   \n",
       "4          5559       1862        1338       4.154709      1.391629   \n",
       "..          ...        ...         ...            ...           ...   \n",
       "298        4810       1627         957       5.026123      1.700104   \n",
       "299        2251        765         459       4.904139      1.666667   \n",
       "300        5540       1898        1151       4.813206      1.649001   \n",
       "301        7763       2650        1631       4.759657      1.624770   \n",
       "302        6169       2052        1258       4.903816      1.631161   \n",
       "\n",
       "     sent_count  ...  poly_word_count  dc_word_perc  gf_word_perc  \\\n",
       "0           112  ...              248      0.308216      0.108410   \n",
       "1            53  ...              188      0.331826      0.146474   \n",
       "2            96  ...              188      0.270903      0.079790   \n",
       "3            51  ...              153      0.340122      0.141548   \n",
       "4            90  ...              130      0.305680      0.088191   \n",
       "..          ...  ...              ...           ...           ...   \n",
       "298          39  ...              178      0.459770      0.168234   \n",
       "299          20  ...               81      0.466231      0.156863   \n",
       "300          46  ...              211      0.422242      0.166811   \n",
       "301          82  ...              290      0.404660      0.156346   \n",
       "302          51  ...              240      0.440382      0.167727   \n",
       "\n",
       "     poly_word_perc        ari  flesch_kincaid  coleman_liau  dale_chall  \\\n",
       "0          0.120564   8.660673        9.034703      8.689587   13.976300   \n",
       "1          0.169982  11.442470       11.560787     10.793960   15.590029   \n",
       "2          0.089823   9.166178        9.239998      7.429890   15.091392   \n",
       "3          0.155804   9.378062       10.172161      9.104766   14.920961   \n",
       "4          0.097160   5.572010        6.629226      6.638655   12.200556   \n",
       "..              ...        ...             ...           ...         ...   \n",
       "298        0.185998  14.512272       14.041233     12.547335   19.430847   \n",
       "299        0.176471  13.143497       13.027167     11.746580   18.744986   \n",
       "300        0.183319  13.751069       13.626689     11.318679   19.077976   \n",
       "301        0.177805  10.933105       11.339482     10.698614   16.255138   \n",
       "302        0.190779  14.000305       13.277695     11.834436   19.188291   \n",
       "\n",
       "     gunning_fog       smog  \n",
       "0      11.682841  11.629938  \n",
       "1      14.206121  13.888447  \n",
       "2      11.912424  11.123544  \n",
       "3      13.363875  13.023867  \n",
       "4       9.474320   9.994967  \n",
       "..           ...        ...  \n",
       "298    16.544747  15.333674  \n",
       "299    15.454510  14.625780  \n",
       "300    16.681154  15.364192  \n",
       "301    14.209930  13.872383  \n",
       "302    16.575729  15.521787  \n",
       "\n",
       "[303 rows x 23 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "84387bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.drop(['text', 'filepath'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "d1179497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>char_count</th>\n",
       "      <th>syl_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_per_word</th>\n",
       "      <th>syl_per_word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>word_per_sent</th>\n",
       "      <th>dc_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>poly_word_count</th>\n",
       "      <th>dc_word_perc</th>\n",
       "      <th>gf_word_perc</th>\n",
       "      <th>poly_word_perc</th>\n",
       "      <th>ari</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>oba</td>\n",
       "      <td>9131</td>\n",
       "      <td>3044</td>\n",
       "      <td>2057</td>\n",
       "      <td>4.438989</td>\n",
       "      <td>1.479825</td>\n",
       "      <td>112</td>\n",
       "      <td>18.366071</td>\n",
       "      <td>634</td>\n",
       "      <td>...</td>\n",
       "      <td>248</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.120564</td>\n",
       "      <td>8.660673</td>\n",
       "      <td>9.034703</td>\n",
       "      <td>8.689587</td>\n",
       "      <td>13.976300</td>\n",
       "      <td>11.682841</td>\n",
       "      <td>11.629938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-12-25</td>\n",
       "      <td>oba</td>\n",
       "      <td>5269</td>\n",
       "      <td>1782</td>\n",
       "      <td>1106</td>\n",
       "      <td>4.764014</td>\n",
       "      <td>1.611212</td>\n",
       "      <td>53</td>\n",
       "      <td>20.867925</td>\n",
       "      <td>367</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.331826</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.169982</td>\n",
       "      <td>11.442470</td>\n",
       "      <td>11.560787</td>\n",
       "      <td>10.793960</td>\n",
       "      <td>15.590029</td>\n",
       "      <td>14.206121</td>\n",
       "      <td>13.888447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>oba</td>\n",
       "      <td>8752</td>\n",
       "      <td>2896</td>\n",
       "      <td>2093</td>\n",
       "      <td>4.181558</td>\n",
       "      <td>1.383660</td>\n",
       "      <td>96</td>\n",
       "      <td>21.802083</td>\n",
       "      <td>567</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.270903</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.089823</td>\n",
       "      <td>9.166178</td>\n",
       "      <td>9.239998</td>\n",
       "      <td>7.429890</td>\n",
       "      <td>15.091392</td>\n",
       "      <td>11.912424</td>\n",
       "      <td>11.123544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-16</td>\n",
       "      <td>oba</td>\n",
       "      <td>4416</td>\n",
       "      <td>1519</td>\n",
       "      <td>982</td>\n",
       "      <td>4.496945</td>\n",
       "      <td>1.546843</td>\n",
       "      <td>51</td>\n",
       "      <td>19.254902</td>\n",
       "      <td>334</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>0.340122</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>0.155804</td>\n",
       "      <td>9.378062</td>\n",
       "      <td>10.172161</td>\n",
       "      <td>9.104766</td>\n",
       "      <td>14.920961</td>\n",
       "      <td>13.363875</td>\n",
       "      <td>13.023867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-29</td>\n",
       "      <td>oba</td>\n",
       "      <td>5559</td>\n",
       "      <td>1862</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.154709</td>\n",
       "      <td>1.391629</td>\n",
       "      <td>90</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>409</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.305680</td>\n",
       "      <td>0.088191</td>\n",
       "      <td>0.097160</td>\n",
       "      <td>5.572010</td>\n",
       "      <td>6.629226</td>\n",
       "      <td>6.638655</td>\n",
       "      <td>12.200556</td>\n",
       "      <td>9.474320</td>\n",
       "      <td>9.994967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>wsj</td>\n",
       "      <td>4810</td>\n",
       "      <td>1627</td>\n",
       "      <td>957</td>\n",
       "      <td>5.026123</td>\n",
       "      <td>1.700104</td>\n",
       "      <td>39</td>\n",
       "      <td>24.538462</td>\n",
       "      <td>440</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.168234</td>\n",
       "      <td>0.185998</td>\n",
       "      <td>14.512272</td>\n",
       "      <td>14.041233</td>\n",
       "      <td>12.547335</td>\n",
       "      <td>19.430847</td>\n",
       "      <td>16.544747</td>\n",
       "      <td>15.333674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>wsj</td>\n",
       "      <td>2251</td>\n",
       "      <td>765</td>\n",
       "      <td>459</td>\n",
       "      <td>4.904139</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>22.950000</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0.466231</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>13.143497</td>\n",
       "      <td>13.027167</td>\n",
       "      <td>11.746580</td>\n",
       "      <td>18.744986</td>\n",
       "      <td>15.454510</td>\n",
       "      <td>14.625780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>wsj</td>\n",
       "      <td>5540</td>\n",
       "      <td>1898</td>\n",
       "      <td>1151</td>\n",
       "      <td>4.813206</td>\n",
       "      <td>1.649001</td>\n",
       "      <td>46</td>\n",
       "      <td>25.021739</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>0.422242</td>\n",
       "      <td>0.166811</td>\n",
       "      <td>0.183319</td>\n",
       "      <td>13.751069</td>\n",
       "      <td>13.626689</td>\n",
       "      <td>11.318679</td>\n",
       "      <td>19.077976</td>\n",
       "      <td>16.681154</td>\n",
       "      <td>15.364192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2012-11-07</td>\n",
       "      <td>wsj</td>\n",
       "      <td>7763</td>\n",
       "      <td>2650</td>\n",
       "      <td>1631</td>\n",
       "      <td>4.759657</td>\n",
       "      <td>1.624770</td>\n",
       "      <td>82</td>\n",
       "      <td>19.890244</td>\n",
       "      <td>660</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>0.404660</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.177805</td>\n",
       "      <td>10.933105</td>\n",
       "      <td>11.339482</td>\n",
       "      <td>10.698614</td>\n",
       "      <td>16.255138</td>\n",
       "      <td>14.209930</td>\n",
       "      <td>13.872383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>wsj</td>\n",
       "      <td>6169</td>\n",
       "      <td>2052</td>\n",
       "      <td>1258</td>\n",
       "      <td>4.903816</td>\n",
       "      <td>1.631161</td>\n",
       "      <td>51</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>0.440382</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>14.000305</td>\n",
       "      <td>13.277695</td>\n",
       "      <td>11.834436</td>\n",
       "      <td>19.188291</td>\n",
       "      <td>16.575729</td>\n",
       "      <td>15.521787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date source  char_count  syl_count  word_count  char_per_word  \\\n",
       "0   2014-07-01    oba        9131       3044        2057       4.438989   \n",
       "1   2009-12-25    oba        5269       1782        1106       4.764014   \n",
       "2   2008-11-05    oba        8752       2896        2093       4.181558   \n",
       "3   2011-12-16    oba        4416       1519         982       4.496945   \n",
       "4   2012-04-29    oba        5559       1862        1338       4.154709   \n",
       "..         ...    ...         ...        ...         ...            ...   \n",
       "298 2014-03-26    wsj        4810       1627         957       5.026123   \n",
       "299 2012-03-31    wsj        2251        765         459       4.904139   \n",
       "300 2014-01-29    wsj        5540       1898        1151       4.813206   \n",
       "301 2012-11-07    wsj        7763       2650        1631       4.759657   \n",
       "302 2016-09-05    wsj        6169       2052        1258       4.903816   \n",
       "\n",
       "     syl_per_word  sent_count  word_per_sent  dc_word_count  ...  \\\n",
       "0        1.479825         112      18.366071            634  ...   \n",
       "1        1.611212          53      20.867925            367  ...   \n",
       "2        1.383660          96      21.802083            567  ...   \n",
       "3        1.546843          51      19.254902            334  ...   \n",
       "4        1.391629          90      14.866667            409  ...   \n",
       "..            ...         ...            ...            ...  ...   \n",
       "298      1.700104          39      24.538462            440  ...   \n",
       "299      1.666667          20      22.950000            214  ...   \n",
       "300      1.649001          46      25.021739            486  ...   \n",
       "301      1.624770          82      19.890244            660  ...   \n",
       "302      1.631161          51      24.666667            554  ...   \n",
       "\n",
       "     poly_word_count  dc_word_perc  gf_word_perc  poly_word_perc        ari  \\\n",
       "0                248      0.308216      0.108410        0.120564   8.660673   \n",
       "1                188      0.331826      0.146474        0.169982  11.442470   \n",
       "2                188      0.270903      0.079790        0.089823   9.166178   \n",
       "3                153      0.340122      0.141548        0.155804   9.378062   \n",
       "4                130      0.305680      0.088191        0.097160   5.572010   \n",
       "..               ...           ...           ...             ...        ...   \n",
       "298              178      0.459770      0.168234        0.185998  14.512272   \n",
       "299               81      0.466231      0.156863        0.176471  13.143497   \n",
       "300              211      0.422242      0.166811        0.183319  13.751069   \n",
       "301              290      0.404660      0.156346        0.177805  10.933105   \n",
       "302              240      0.440382      0.167727        0.190779  14.000305   \n",
       "\n",
       "     flesch_kincaid  coleman_liau  dale_chall  gunning_fog       smog  \n",
       "0          9.034703      8.689587   13.976300    11.682841  11.629938  \n",
       "1         11.560787     10.793960   15.590029    14.206121  13.888447  \n",
       "2          9.239998      7.429890   15.091392    11.912424  11.123544  \n",
       "3         10.172161      9.104766   14.920961    13.363875  13.023867  \n",
       "4          6.629226      6.638655   12.200556     9.474320   9.994967  \n",
       "..              ...           ...         ...          ...        ...  \n",
       "298       14.041233     12.547335   19.430847    16.544747  15.333674  \n",
       "299       13.027167     11.746580   18.744986    15.454510  14.625780  \n",
       "300       13.626689     11.318679   19.077976    16.681154  15.364192  \n",
       "301       11.339482     10.698614   16.255138    14.209930  13.872383  \n",
       "302       13.277695     11.834436   19.188291    16.575729  15.521787  \n",
       "\n",
       "[303 rows x 21 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "c7ec60f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>depth</th>\n",
       "      <th>TBsubjectivity</th>\n",
       "      <th>TBpolarity</th>\n",
       "      <th>words_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.064416</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.130252</td>\n",
       "      <td>47</td>\n",
       "      <td>1459</td>\n",
       "      <td>620</td>\n",
       "      <td>7.276596</td>\n",
       "      <td>0.406976</td>\n",
       "      <td>0.135880</td>\n",
       "      <td>31.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>0.064398</td>\n",
       "      <td>0.064471</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.048739</td>\n",
       "      <td>0.159664</td>\n",
       "      <td>217</td>\n",
       "      <td>5856</td>\n",
       "      <td>939</td>\n",
       "      <td>5.986175</td>\n",
       "      <td>0.445383</td>\n",
       "      <td>0.167408</td>\n",
       "      <td>26.986175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.072536</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.070185</td>\n",
       "      <td>0.071579</td>\n",
       "      <td>0.072456</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.168498</td>\n",
       "      <td>64</td>\n",
       "      <td>1709</td>\n",
       "      <td>657</td>\n",
       "      <td>6.421875</td>\n",
       "      <td>0.424590</td>\n",
       "      <td>0.178206</td>\n",
       "      <td>26.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.065636</td>\n",
       "      <td>0.065602</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.065266</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079618</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.114650</td>\n",
       "      <td>54</td>\n",
       "      <td>1862</td>\n",
       "      <td>735</td>\n",
       "      <td>7.259259</td>\n",
       "      <td>0.412085</td>\n",
       "      <td>0.115966</td>\n",
       "      <td>34.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.064371</td>\n",
       "      <td>0.067174</td>\n",
       "      <td>0.067145</td>\n",
       "      <td>0.067260</td>\n",
       "      <td>0.066802</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>96</td>\n",
       "      <td>2254</td>\n",
       "      <td>755</td>\n",
       "      <td>5.760417</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.144582</td>\n",
       "      <td>23.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>0.069178</td>\n",
       "      <td>0.069730</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.069329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.187075</td>\n",
       "      <td>79</td>\n",
       "      <td>1303</td>\n",
       "      <td>470</td>\n",
       "      <td>4.392405</td>\n",
       "      <td>0.490976</td>\n",
       "      <td>0.237315</td>\n",
       "      <td>16.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.069166</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.068939</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.068078</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.152727</td>\n",
       "      <td>61</td>\n",
       "      <td>1446</td>\n",
       "      <td>623</td>\n",
       "      <td>6.098361</td>\n",
       "      <td>0.397283</td>\n",
       "      <td>0.114535</td>\n",
       "      <td>23.704918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.068761</td>\n",
       "      <td>0.069864</td>\n",
       "      <td>0.067920</td>\n",
       "      <td>0.065872</td>\n",
       "      <td>0.069811</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.070074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073826</td>\n",
       "      <td>0.057047</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>53</td>\n",
       "      <td>1275</td>\n",
       "      <td>558</td>\n",
       "      <td>5.679245</td>\n",
       "      <td>0.454084</td>\n",
       "      <td>0.178910</td>\n",
       "      <td>24.056604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.066897</td>\n",
       "      <td>0.066921</td>\n",
       "      <td>0.066529</td>\n",
       "      <td>0.066823</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.066885</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.066493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050076</td>\n",
       "      <td>0.044765</td>\n",
       "      <td>0.157815</td>\n",
       "      <td>231</td>\n",
       "      <td>5143</td>\n",
       "      <td>1592</td>\n",
       "      <td>4.900433</td>\n",
       "      <td>0.500204</td>\n",
       "      <td>0.182039</td>\n",
       "      <td>22.264069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.072179</td>\n",
       "      <td>0.071380</td>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>0.071037</td>\n",
       "      <td>0.071608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>0.190789</td>\n",
       "      <td>20</td>\n",
       "      <td>608</td>\n",
       "      <td>325</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.402340</td>\n",
       "      <td>0.126560</td>\n",
       "      <td>30.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date source       ADJ       ADP       ADV       AUX     CCONJ  \\\n",
       "0   2008-06-04    nyt  0.064458  0.065088  0.062400  0.064962  0.064416   \n",
       "1   2008-06-04    oba  0.064649  0.064670  0.064440  0.064398  0.064471   \n",
       "2   2008-06-04    wsj  0.072536  0.071300  0.070185  0.071579  0.072456   \n",
       "3   2008-11-05    nyt  0.065299  0.065636  0.065602  0.064593  0.065131   \n",
       "4   2008-11-05    oba  0.067288  0.067345  0.064371  0.067174  0.067145   \n",
       "..         ...    ...       ...       ...       ...       ...       ...   \n",
       "295 2016-11-09    oba  0.069479  0.069178  0.069730  0.069078  0.068376   \n",
       "296 2016-11-09    wsj  0.069166  0.068667  0.068939  0.068576  0.068078   \n",
       "297 2017-01-11    nyt  0.068761  0.069864  0.067920  0.065872  0.069811   \n",
       "298 2017-01-11    oba  0.066897  0.066921  0.066529  0.066823  0.066811   \n",
       "299 2017-01-11    wsj  0.072179  0.071380  0.071494  0.069095  0.071037   \n",
       "\n",
       "          DET      INTJ      NOUN  ...   sadness  surprise     trust  \\\n",
       "0    0.063408  0.055598  0.064920  ...  0.075630  0.046218  0.130252   \n",
       "1    0.064638  0.054967  0.064503  ...  0.042017  0.048739  0.159664   \n",
       "2    0.072177  0.000000  0.072616  ...  0.054945  0.047619  0.168498   \n",
       "3    0.065266  0.042603  0.065972  ...  0.079618  0.041401  0.114650   \n",
       "4    0.067260  0.066802  0.066745  ...  0.062222  0.046667  0.160000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  0.069429  0.042841  0.069329  ...  0.034014  0.091837  0.187075   \n",
       "296  0.069120  0.000000  0.069211  ...  0.076364  0.080000  0.152727   \n",
       "297  0.069916  0.041708  0.070074  ...  0.073826  0.057047  0.161074   \n",
       "298  0.066885  0.066676  0.066493  ...  0.050076  0.044765  0.157815   \n",
       "299  0.071608  0.000000  0.072293  ...  0.085526  0.046053  0.190789   \n",
       "\n",
       "     num_sents  num_words  num_unique_words     depth  TBsubjectivity  \\\n",
       "0           47       1459               620  7.276596        0.406976   \n",
       "1          217       5856               939  5.986175        0.445383   \n",
       "2           64       1709               657  6.421875        0.424590   \n",
       "3           54       1862               735  7.259259        0.412085   \n",
       "4           96       2254               755  5.760417        0.435926   \n",
       "..         ...        ...               ...       ...             ...   \n",
       "295         79       1303               470  4.392405        0.490976   \n",
       "296         61       1446               623  6.098361        0.397283   \n",
       "297         53       1275               558  5.679245        0.454084   \n",
       "298        231       5143              1592  4.900433        0.500204   \n",
       "299         20        608               325  7.300000        0.402340   \n",
       "\n",
       "    TBpolarity  words_per_sentence  \n",
       "0     0.135880           31.042553  \n",
       "1     0.167408           26.986175  \n",
       "2     0.178206           26.703125  \n",
       "3     0.115966           34.481481  \n",
       "4     0.144582           23.479167  \n",
       "..         ...                 ...  \n",
       "295   0.237315           16.493671  \n",
       "296   0.114535           23.704918  \n",
       "297   0.178910           24.056604  \n",
       "298   0.182039           22.264069  \n",
       "299   0.126560           30.400000  \n",
       "\n",
       "[300 rows x 38 columns]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "fac69957",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.merge(tidy_data, text_df, on=['source', 'date'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "231687dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>...</th>\n",
       "      <th>poly_word_count</th>\n",
       "      <th>dc_word_perc</th>\n",
       "      <th>gf_word_perc</th>\n",
       "      <th>poly_word_perc</th>\n",
       "      <th>ari</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.064416</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>0.380171</td>\n",
       "      <td>0.157632</td>\n",
       "      <td>0.177603</td>\n",
       "      <td>15.452576</td>\n",
       "      <td>15.325928</td>\n",
       "      <td>10.632325</td>\n",
       "      <td>20.798477</td>\n",
       "      <td>18.237193</td>\n",
       "      <td>16.278189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>0.064398</td>\n",
       "      <td>0.064471</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>...</td>\n",
       "      <td>692</td>\n",
       "      <td>0.291358</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>0.122046</td>\n",
       "      <td>12.214807</td>\n",
       "      <td>11.736337</td>\n",
       "      <td>8.759753</td>\n",
       "      <td>17.560543</td>\n",
       "      <td>14.811401</td>\n",
       "      <td>13.330696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-04</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.072536</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.070185</td>\n",
       "      <td>0.071579</td>\n",
       "      <td>0.072456</td>\n",
       "      <td>0.072177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072616</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>0.422932</td>\n",
       "      <td>0.169799</td>\n",
       "      <td>0.181078</td>\n",
       "      <td>13.762434</td>\n",
       "      <td>13.247780</td>\n",
       "      <td>11.381454</td>\n",
       "      <td>19.047102</td>\n",
       "      <td>16.766980</td>\n",
       "      <td>15.268686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.065636</td>\n",
       "      <td>0.065602</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.065266</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>...</td>\n",
       "      <td>305</td>\n",
       "      <td>0.367757</td>\n",
       "      <td>0.156053</td>\n",
       "      <td>0.174986</td>\n",
       "      <td>16.572693</td>\n",
       "      <td>16.143715</td>\n",
       "      <td>10.577900</td>\n",
       "      <td>21.816657</td>\n",
       "      <td>19.153222</td>\n",
       "      <td>16.705917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-11-05</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.064371</td>\n",
       "      <td>0.067174</td>\n",
       "      <td>0.067145</td>\n",
       "      <td>0.067260</td>\n",
       "      <td>0.066802</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.270903</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.089823</td>\n",
       "      <td>9.166178</td>\n",
       "      <td>9.239998</td>\n",
       "      <td>7.429890</td>\n",
       "      <td>15.091392</td>\n",
       "      <td>11.912424</td>\n",
       "      <td>11.123544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>0.069178</td>\n",
       "      <td>0.069730</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.069329</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.249196</td>\n",
       "      <td>0.106109</td>\n",
       "      <td>0.115756</td>\n",
       "      <td>6.142879</td>\n",
       "      <td>6.942263</td>\n",
       "      <td>6.913215</td>\n",
       "      <td>11.745237</td>\n",
       "      <td>10.543107</td>\n",
       "      <td>10.841910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.069166</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.068939</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.068078</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069211</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.413254</td>\n",
       "      <td>0.137007</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>12.226879</td>\n",
       "      <td>11.895723</td>\n",
       "      <td>11.130335</td>\n",
       "      <td>17.445410</td>\n",
       "      <td>14.286825</td>\n",
       "      <td>13.854148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0.068761</td>\n",
       "      <td>0.069864</td>\n",
       "      <td>0.067920</td>\n",
       "      <td>0.065872</td>\n",
       "      <td>0.069811</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.070074</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>0.417029</td>\n",
       "      <td>0.159861</td>\n",
       "      <td>0.174631</td>\n",
       "      <td>11.795875</td>\n",
       "      <td>12.102038</td>\n",
       "      <td>10.760626</td>\n",
       "      <td>17.356505</td>\n",
       "      <td>15.081232</td>\n",
       "      <td>14.254228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>oba</td>\n",
       "      <td>0.066897</td>\n",
       "      <td>0.066921</td>\n",
       "      <td>0.066529</td>\n",
       "      <td>0.066823</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.066885</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.066493</td>\n",
       "      <td>...</td>\n",
       "      <td>631</td>\n",
       "      <td>0.323535</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>0.129702</td>\n",
       "      <td>10.026644</td>\n",
       "      <td>10.249659</td>\n",
       "      <td>8.919137</td>\n",
       "      <td>15.554685</td>\n",
       "      <td>13.143667</td>\n",
       "      <td>12.570875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>wsj</td>\n",
       "      <td>0.072179</td>\n",
       "      <td>0.071380</td>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>0.071037</td>\n",
       "      <td>0.071608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072293</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.171986</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>15.986170</td>\n",
       "      <td>15.158355</td>\n",
       "      <td>12.258440</td>\n",
       "      <td>20.566367</td>\n",
       "      <td>18.159433</td>\n",
       "      <td>16.342720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date source       ADJ       ADP       ADV       AUX     CCONJ  \\\n",
       "0   2008-06-04    nyt  0.064458  0.065088  0.062400  0.064962  0.064416   \n",
       "1   2008-06-04    oba  0.064649  0.064670  0.064440  0.064398  0.064471   \n",
       "2   2008-06-04    wsj  0.072536  0.071300  0.070185  0.071579  0.072456   \n",
       "3   2008-11-05    nyt  0.065299  0.065636  0.065602  0.064593  0.065131   \n",
       "4   2008-11-05    oba  0.067288  0.067345  0.064371  0.067174  0.067145   \n",
       "..         ...    ...       ...       ...       ...       ...       ...   \n",
       "295 2016-11-09    oba  0.069479  0.069178  0.069730  0.069078  0.068376   \n",
       "296 2016-11-09    wsj  0.069166  0.068667  0.068939  0.068576  0.068078   \n",
       "297 2017-01-11    nyt  0.068761  0.069864  0.067920  0.065872  0.069811   \n",
       "298 2017-01-11    oba  0.066897  0.066921  0.066529  0.066823  0.066811   \n",
       "299 2017-01-11    wsj  0.072179  0.071380  0.071494  0.069095  0.071037   \n",
       "\n",
       "          DET      INTJ      NOUN  ...  poly_word_count  dc_word_perc  \\\n",
       "0    0.063408  0.055598  0.064920  ...              249      0.380171   \n",
       "1    0.064638  0.054967  0.064503  ...              692      0.291358   \n",
       "2    0.072177  0.000000  0.072616  ...              289      0.422932   \n",
       "3    0.065266  0.042603  0.065972  ...              305      0.367757   \n",
       "4    0.067260  0.066802  0.066745  ...              188      0.270903   \n",
       "..        ...       ...       ...  ...              ...           ...   \n",
       "295  0.069429  0.042841  0.069329  ...              144      0.249196   \n",
       "296  0.069120  0.000000  0.069211  ...              215      0.413254   \n",
       "297  0.069916  0.041708  0.070074  ...              201      0.417029   \n",
       "298  0.066885  0.066676  0.066493  ...              631      0.323535   \n",
       "299  0.071608  0.000000  0.072293  ...              107      0.416667   \n",
       "\n",
       "     gf_word_perc  poly_word_perc        ari  flesch_kincaid  coleman_liau  \\\n",
       "0        0.157632        0.177603  15.452576       15.325928     10.632325   \n",
       "1        0.108995        0.122046  12.214807       11.736337      8.759753   \n",
       "2        0.169799        0.181078  13.762434       13.247780     11.381454   \n",
       "3        0.156053        0.174986  16.572693       16.143715     10.577900   \n",
       "4        0.079790        0.089823   9.166178        9.239998      7.429890   \n",
       "..            ...             ...        ...             ...           ...   \n",
       "295      0.106109        0.115756   6.142879        6.942263      6.913215   \n",
       "296      0.137007        0.160089  12.226879       11.895723     11.130335   \n",
       "297      0.159861        0.174631  11.795875       12.102038     10.760626   \n",
       "298      0.117986        0.129702  10.026644       10.249659      8.919137   \n",
       "299      0.171986        0.189716  15.986170       15.158355     12.258440   \n",
       "\n",
       "     dale_chall gunning_fog       smog  \n",
       "0     20.798477   18.237193  16.278189  \n",
       "1     17.560543   14.811401  13.330696  \n",
       "2     19.047102   16.766980  15.268686  \n",
       "3     21.816657   19.153222  16.705917  \n",
       "4     15.091392   11.912424  11.123544  \n",
       "..          ...         ...        ...  \n",
       "295   11.745237   10.543107  10.841910  \n",
       "296   17.445410   14.286825  13.854148  \n",
       "297   17.356505   15.081232  14.254228  \n",
       "298   15.554685   13.143667  12.570875  \n",
       "299   20.566367   18.159433  16.342720  \n",
       "\n",
       "[300 rows x 57 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dba873",
   "metadata": {},
   "source": [
    "### Save to csv, leave commented to not accidently write over existing file by accident with trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "c712b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "#new.to_csv('tidy_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49408aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
