{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51825e42",
   "metadata": {},
   "source": [
    "### Exploring dependency tree parsing using stanza and also CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738e4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "import spacy\n",
    "import stanza\n",
    "import en_core_web_md\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "word_token = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29554c8a",
   "metadata": {},
   "source": [
    "### Load up the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b5e575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>word_set</th>\n",
       "      <th>num_unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Chairman Dean and my great friend Dick Durb...</td>\n",
       "      <td>./GWB/address-accepting-the-presidential-nomin...</td>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>[To Chairman Dean and my great friend Dick Dur...</td>\n",
       "      <td>[To, Chairman, Dean, and, my, great, friend, D...</td>\n",
       "      <td>226</td>\n",
       "      <td>5080</td>\n",
       "      <td>{land, hands., compassionate, rise, challengin...</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you. Thank you all very much. Thank you....</td>\n",
       "      <td>./GWB/address-accepting-the-presidential-nomin...</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>gwb</td>\n",
       "      <td>[Thank you., Thank you all very much., Thank y...</td>\n",
       "      <td>[Thank, you., Thank, you, all, very, much., Th...</td>\n",
       "      <td>310</td>\n",
       "      <td>4802</td>\n",
       "      <td>{land, rise, jobs, legislate, Thanks., constan...</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Speaker, Vice President Cheney, Members of...</td>\n",
       "      <td>./GWB/address-before-joint-session-the-congres...</td>\n",
       "      <td>2006-01-31</td>\n",
       "      <td>gwb</td>\n",
       "      <td>[Mr. Speaker, Vice President Cheney, Members o...</td>\n",
       "      <td>[Mr., Speaker, ,, Vice, President, Cheney, ,, ...</td>\n",
       "      <td>238</td>\n",
       "      <td>5395</td>\n",
       "      <td>{hearts, Pflugerville, rise, minorities, compr...</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  To Chairman Dean and my great friend Dick Durb...   \n",
       "1  Thank you. Thank you all very much. Thank you....   \n",
       "2  Mr. Speaker, Vice President Cheney, Members of...   \n",
       "\n",
       "                                            filepath       date source  \\\n",
       "0  ./GWB/address-accepting-the-presidential-nomin... 2008-06-03    gwb   \n",
       "1  ./GWB/address-accepting-the-presidential-nomin... 2008-09-04    gwb   \n",
       "2  ./GWB/address-before-joint-session-the-congres... 2006-01-31    gwb   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [To Chairman Dean and my great friend Dick Dur...   \n",
       "1  [Thank you., Thank you all very much., Thank y...   \n",
       "2  [Mr. Speaker, Vice President Cheney, Members o...   \n",
       "\n",
       "                                               words  num_sents  num_words  \\\n",
       "0  [To, Chairman, Dean, and, my, great, friend, D...        226       5080   \n",
       "1  [Thank, you., Thank, you, all, very, much., Th...        310       4802   \n",
       "2  [Mr., Speaker, ,, Vice, President, Cheney, ,, ...        238       5395   \n",
       "\n",
       "                                            word_set  num_unique_words  \n",
       "0  {land, hands., compassionate, rise, challengin...              1349  \n",
       "1  {land, rise, jobs, legislate, Thanks., constan...              1343  \n",
       "2  {hearts, Pflugerville, rise, minorities, compr...              1655  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the files\n",
    "#paths = ['./speeches/', './NYTimes/', './WSJ/'] \n",
    "paths = ['./GWB/']\n",
    "list_of_files = []\n",
    "\n",
    "dates = pd.read_csv('dateSpeeches.csv')\n",
    "dates = pd.read_csv('speech_and_date_gwb.csv')\n",
    "for path in paths:\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                list_of_files.append(os.path.join(root,file))\n",
    "\n",
    "speeches = []\n",
    "for file in list_of_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        #print(file)\n",
    "        text = f.read()\n",
    "    f.close()\n",
    "    speeches.append([text, file])\n",
    "\n",
    "#clean out goofy unicode  space characters \n",
    "speeches = [(unicodedata.normalize(\"NFKD\", speech[0]), speech[1]) for speech in speeches if len(speech)>0 ]\n",
    "\n",
    "# remove [stuff] in between square brackets\n",
    "def remove_bracket(text):\n",
    "    return re.sub('(\\[[^w]*\\]\\s)', '',text)\n",
    "speeches = [(remove_bracket(speech[0]), speech[1]) for speech in speeches]\n",
    "\n",
    "def get_source(text):\n",
    "    regex = \"[^./][a-zA-Z]+[^/]\"\n",
    "    string = re.findall(regex, str(text))[0]\n",
    "    if string == 'speeches': string = 'oba'\n",
    "    if string == 'NYTimes': string = 'nyt'\n",
    "    return string.lower()\n",
    "\n",
    "def get_date(text):\n",
    "    regex = \"([0-9]+[\\-][0-9]+[\\-][0-9]+)\"\n",
    "    return re.findall(regex, str(text))[0]\n",
    "\n",
    "def get_filename(text):\n",
    "    regex = \"[-]([a-zA-Z]+)\"\n",
    "    return re.findall(regex, str(text))[0]\n",
    "\n",
    "cols = ['text', 'filepath']\n",
    "text_df = pd.DataFrame(speeches, columns=cols)\n",
    "# A couple tweaks for the GWB data\n",
    "dates['file'] = [ file.replace('GWB/', './GWB/') for file in dates['file'] ]\n",
    "dates = dates.rename(columns={\"file\": \"filepath\"})\n",
    "#text_df['date'] = text_df['filepath'].apply(get_date)\n",
    "text_df = pd.merge(text_df, dates, how='left', on='filepath')\n",
    "text_df['date'] = pd.to_datetime(text_df['date'], format='%Y-%m-%d')\n",
    "text_df['source'] = text_df['filepath'].apply(get_source)\n",
    "\n",
    "text_df['sentences'] = text_df['text'].apply(sent_tokenize)\n",
    "text_df['words'] = text_df['text'].apply(word_token.tokenize)\n",
    "text_df['num_sents'] = text_df['sentences'].apply(len)\n",
    "text_df['num_words'] = text_df['words'].apply(len)\n",
    "text_df['word_set'] = text_df['words'].apply(set)\n",
    "text_df['num_unique_words'] = text_df['word_set'].apply(len)\n",
    "text_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a037a1",
   "metadata": {},
   "source": [
    "<A HREF=\"https://textblob.readthedocs.io/en/latest/quickstart.html\">TextBlob Quickstart guide</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3633e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['TBsubjectivity']=[TextBlob(text).sentiment.subjectivity for text in text_df['text']]\n",
    "text_df['TBpolarity']=[TextBlob(text).sentiment.polarity for text in text_df['text']]\n",
    "#text_df.to_csv('numwords_TBpolar_gwb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a08e2b",
   "metadata": {},
   "source": [
    "<A HREF=\"https://plotly.com/python/plotly-express/\">Plotly Express</A><BR><A HREF=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\">Pandas cheat sheet</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cda881",
   "metadata": {},
   "source": [
    "<A HREF=\"https://universaldependencies.org/u/pos/\">Universal POS tags</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcd107",
   "metadata": {},
   "source": [
    "<A HREF=\"https://en.wikipedia.org/wiki/Interjection\">Wikipedia - Interjections</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a64d1",
   "metadata": {},
   "source": [
    "<A HREF=\"https://pypi.org/project/NRCLex/\">NRCLex</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce01fae",
   "metadata": {},
   "source": [
    "### Attempt 1. Stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca14c82",
   "metadata": {},
   "source": [
    "### <A HREF=\"https://stanfordnlp.github.io/stanza/getting_started.html\">Stanza quickstart guide</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac01a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 10:50:47 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af876727c8cd47a78cb34a9ff073d0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 10:50:49 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-26 10:50:49 INFO: Use device: gpu\n",
      "2023-03-26 10:50:49 INFO: Loading: tokenize\n",
      "2023-03-26 10:50:51 INFO: Loading: pos\n",
      "2023-03-26 10:50:51 INFO: Loading: lemma\n",
      "2023-03-26 10:50:51 INFO: Loading: depparse\n",
      "2023-03-26 10:50:52 INFO: Loading: sentiment\n",
      "2023-03-26 10:50:52 INFO: Loading: constituency\n",
      "2023-03-26 10:50:53 INFO: Loading: ner\n",
      "2023-03-26 10:50:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\") # Initialize the default English pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c295d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"Many\",\n",
       "      \"lemma\": \"many\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"JJ\",\n",
       "      \"feats\": \"Degree=Pos\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"amod\",\n",
       "      \"start_char\": 0,\n",
       "      \"end_char\": 4,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"scientists\",\n",
       "      \"lemma\": \"scientist\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 5,\n",
       "      \"end_char\": 15,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"believe\",\n",
       "      \"lemma\": \"believe\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBP\",\n",
       "      \"feats\": \"Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"start_char\": 16,\n",
       "      \"end_char\": 23,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"that\",\n",
       "      \"lemma\": \"that\",\n",
       "      \"upos\": \"SCONJ\",\n",
       "      \"xpos\": \"IN\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"mark\",\n",
       "      \"start_char\": 24,\n",
       "      \"end_char\": 28,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \"embryonic\",\n",
       "      \"lemma\": \"embryonic\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"JJ\",\n",
       "      \"feats\": \"Degree=Pos\",\n",
       "      \"head\": 8,\n",
       "      \"deprel\": \"amod\",\n",
       "      \"start_char\": 29,\n",
       "      \"end_char\": 38,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"stem\",\n",
       "      \"lemma\": \"stem\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 8,\n",
       "      \"deprel\": \"compound\",\n",
       "      \"start_char\": 39,\n",
       "      \"end_char\": 43,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \"cell\",\n",
       "      \"lemma\": \"cell\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 8,\n",
       "      \"deprel\": \"compound\",\n",
       "      \"start_char\": 44,\n",
       "      \"end_char\": 48,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 8,\n",
       "      \"text\": \"research\",\n",
       "      \"lemma\": \"research\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 49,\n",
       "      \"end_char\": 57,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 9,\n",
       "      \"text\": \"may\",\n",
       "      \"lemma\": \"may\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"MD\",\n",
       "      \"feats\": \"VerbForm=Fin\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"aux\",\n",
       "      \"start_char\": 58,\n",
       "      \"end_char\": 61,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 10,\n",
       "      \"text\": \"eventually\",\n",
       "      \"lemma\": \"eventually\",\n",
       "      \"upos\": \"ADV\",\n",
       "      \"xpos\": \"RB\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"advmod\",\n",
       "      \"start_char\": 62,\n",
       "      \"end_char\": 72,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 11,\n",
       "      \"text\": \"lead\",\n",
       "      \"lemma\": \"lead\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VB\",\n",
       "      \"feats\": \"VerbForm=Inf\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"ccomp\",\n",
       "      \"start_char\": 73,\n",
       "      \"end_char\": 77,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 12,\n",
       "      \"text\": \"to\",\n",
       "      \"lemma\": \"to\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"IN\",\n",
       "      \"head\": 13,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 78,\n",
       "      \"end_char\": 80,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 13,\n",
       "      \"text\": \"therapies\",\n",
       "      \"lemma\": \"therapy\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"obl\",\n",
       "      \"start_char\": 81,\n",
       "      \"end_char\": 90,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 14,\n",
       "      \"text\": \"that\",\n",
       "      \"lemma\": \"that\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"WDT\",\n",
       "      \"feats\": \"PronType=Rel\",\n",
       "      \"head\": 17,\n",
       "      \"deprel\": \"nsubj:pass\",\n",
       "      \"start_char\": 91,\n",
       "      \"end_char\": 95,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 15,\n",
       "      \"text\": \"could\",\n",
       "      \"lemma\": \"could\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"MD\",\n",
       "      \"feats\": \"VerbForm=Fin\",\n",
       "      \"head\": 17,\n",
       "      \"deprel\": \"aux\",\n",
       "      \"start_char\": 96,\n",
       "      \"end_char\": 101,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 16,\n",
       "      \"text\": \"be\",\n",
       "      \"lemma\": \"be\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"VB\",\n",
       "      \"feats\": \"VerbForm=Inf\",\n",
       "      \"head\": 17,\n",
       "      \"deprel\": \"aux:pass\",\n",
       "      \"start_char\": 102,\n",
       "      \"end_char\": 104,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 17,\n",
       "      \"text\": \"used\",\n",
       "      \"lemma\": \"use\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBN\",\n",
       "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
       "      \"head\": 13,\n",
       "      \"deprel\": \"acl:relcl\",\n",
       "      \"start_char\": 105,\n",
       "      \"end_char\": 109,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 18,\n",
       "      \"text\": \"to\",\n",
       "      \"lemma\": \"to\",\n",
       "      \"upos\": \"PART\",\n",
       "      \"xpos\": \"TO\",\n",
       "      \"head\": 19,\n",
       "      \"deprel\": \"mark\",\n",
       "      \"start_char\": 110,\n",
       "      \"end_char\": 112,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 19,\n",
       "      \"text\": \"treat\",\n",
       "      \"lemma\": \"treat\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VB\",\n",
       "      \"feats\": \"VerbForm=Inf\",\n",
       "      \"head\": 17,\n",
       "      \"deprel\": \"xcomp\",\n",
       "      \"start_char\": 113,\n",
       "      \"end_char\": 118,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 20,\n",
       "      \"text\": \"diseases\",\n",
       "      \"lemma\": \"disease\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 19,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 119,\n",
       "      \"end_char\": 127,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 21,\n",
       "      \"text\": \"that\",\n",
       "      \"lemma\": \"that\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"WDT\",\n",
       "      \"feats\": \"PronType=Rel\",\n",
       "      \"head\": 22,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 128,\n",
       "      \"end_char\": 132,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 22,\n",
       "      \"text\": \"afflict\",\n",
       "      \"lemma\": \"afflict\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBP\",\n",
       "      \"feats\": \"Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 20,\n",
       "      \"deprel\": \"acl:relcl\",\n",
       "      \"start_char\": 133,\n",
       "      \"end_char\": 140,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 23,\n",
       "      \"text\": \"approximately\",\n",
       "      \"lemma\": \"approximately\",\n",
       "      \"upos\": \"ADV\",\n",
       "      \"xpos\": \"RB\",\n",
       "      \"head\": 25,\n",
       "      \"deprel\": \"advmod\",\n",
       "      \"start_char\": 141,\n",
       "      \"end_char\": 154,\n",
       "      \"ner\": \"B-CARDINAL\",\n",
       "      \"multi_ner\": [\n",
       "        \"B-CARDINAL\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 24,\n",
       "      \"text\": \"128\",\n",
       "      \"lemma\": \"128\",\n",
       "      \"upos\": \"NUM\",\n",
       "      \"xpos\": \"CD\",\n",
       "      \"feats\": \"NumForm=Digit|NumType=Card\",\n",
       "      \"head\": 25,\n",
       "      \"deprel\": \"compound\",\n",
       "      \"start_char\": 155,\n",
       "      \"end_char\": 158,\n",
       "      \"ner\": \"I-CARDINAL\",\n",
       "      \"multi_ner\": [\n",
       "        \"I-CARDINAL\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 25,\n",
       "      \"text\": \"million\",\n",
       "      \"lemma\": \"million\",\n",
       "      \"upos\": \"NUM\",\n",
       "      \"xpos\": \"CD\",\n",
       "      \"feats\": \"NumForm=Word|NumType=Card\",\n",
       "      \"head\": 26,\n",
       "      \"deprel\": \"nummod\",\n",
       "      \"start_char\": 159,\n",
       "      \"end_char\": 166,\n",
       "      \"ner\": \"E-CARDINAL\",\n",
       "      \"multi_ner\": [\n",
       "        \"E-CARDINAL\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 26,\n",
       "      \"text\": \"Americans\",\n",
       "      \"lemma\": \"American\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"NNPS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 22,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 167,\n",
       "      \"end_char\": 176,\n",
       "      \"ner\": \"S-NORP\",\n",
       "      \"multi_ner\": [\n",
       "        \"S-NORP\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 27,\n",
       "      \"text\": \".\",\n",
       "      \"lemma\": \".\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"xpos\": \".\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"punct\",\n",
       "      \"start_char\": 176,\n",
       "      \"end_char\": 177,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intxt=stanza.Document([], text=[sentence for sentence in text_df['sentences']][20][20])\n",
    "out=nlp(intxt)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db8bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Many\thead id: 2\thead: scientists\tdeprel: amod\n",
      "id: 2\tword: scientists\thead id: 3\thead: believe\tdeprel: nsubj\n",
      "id: 3\tword: believe\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: that\thead id: 11\thead: lead\tdeprel: mark\n",
      "id: 5\tword: embryonic\thead id: 8\thead: research\tdeprel: amod\n",
      "id: 6\tword: stem\thead id: 8\thead: research\tdeprel: compound\n",
      "id: 7\tword: cell\thead id: 8\thead: research\tdeprel: compound\n",
      "id: 8\tword: research\thead id: 11\thead: lead\tdeprel: nsubj\n",
      "id: 9\tword: may\thead id: 11\thead: lead\tdeprel: aux\n",
      "id: 10\tword: eventually\thead id: 11\thead: lead\tdeprel: advmod\n",
      "id: 11\tword: lead\thead id: 3\thead: believe\tdeprel: ccomp\n",
      "id: 12\tword: to\thead id: 13\thead: therapies\tdeprel: case\n",
      "id: 13\tword: therapies\thead id: 11\thead: lead\tdeprel: obl\n",
      "id: 14\tword: that\thead id: 17\thead: used\tdeprel: nsubj:pass\n",
      "id: 15\tword: could\thead id: 17\thead: used\tdeprel: aux\n",
      "id: 16\tword: be\thead id: 17\thead: used\tdeprel: aux:pass\n",
      "id: 17\tword: used\thead id: 13\thead: therapies\tdeprel: acl:relcl\n",
      "id: 18\tword: to\thead id: 19\thead: treat\tdeprel: mark\n",
      "id: 19\tword: treat\thead id: 17\thead: used\tdeprel: xcomp\n",
      "id: 20\tword: diseases\thead id: 19\thead: treat\tdeprel: obj\n",
      "id: 21\tword: that\thead id: 22\thead: afflict\tdeprel: nsubj\n",
      "id: 22\tword: afflict\thead id: 20\thead: diseases\tdeprel: acl:relcl\n",
      "id: 23\tword: approximately\thead id: 25\thead: million\tdeprel: advmod\n",
      "id: 24\tword: 128\thead id: 25\thead: million\tdeprel: compound\n",
      "id: 25\tword: million\thead id: 26\thead: Americans\tdeprel: nummod\n",
      "id: 26\tword: Americans\thead id: 22\thead: afflict\tdeprel: obj\n",
      "id: 27\tword: .\thead id: 3\thead: believe\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in out.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29dc83",
   "metadata": {},
   "source": [
    "### Attempt 2. Stanford's CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fbe0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stanford's CoreNLP parser with NLTK\n",
    "# 1. Download CoreNLP from https://stanfordnlp.github.io/CoreNLP/download.html\n",
    "# 2. make sure Java is installed, otherwise download and install Java - https://www.java.com/en/download/windows_manual.jsp\n",
    "# 3. Unzip/extract CoreNLP zip file to a directory\n",
    "# 4. Go to that directory and open a command terminal, and run the following command...\n",
    "# 4b. on my laptop its in C:\\Users\\peter\\stanford-corenlp-4.5.2\n",
    "# 5. java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "# 6. Now for graphviz if you want to view the parse trees, download from https://graphviz.org/download/ then install\n",
    "# 7. Now, can run the following python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a8c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLPServer\n"
     ]
    }
   ],
   "source": [
    "# Can try this here, but may have to run from cmd terminal before continuing\n",
    "!java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "973ce316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15f327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09006e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dep_tree.png'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp = CoreNLPDependencyParser()\n",
    "sentence = [sentence for sentence in text_df['sentences']][20][20]\n",
    "result = list(sdp.raw_parse(sentence))\n",
    "dep_tree_dot_repr = [parse for parse in result][0].to_dot()\n",
    "source = Source(dep_tree_dot_repr, filename=\"dep_tree\", format='png')\n",
    "source.view()\n",
    "# Opens in pop-under window... well isn't that nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80379c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"831pt\" height=\"1001pt\"\n",
       " viewBox=\"0.00 0.00 831.00 1001.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 997)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-997 827,-997 827,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-971.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-884.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3 (believe)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263,-957.21C263,-945.8 263,-930.43 263,-917.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"266.5,-917.27 263,-907.27 259.5,-917.27 266.5,-917.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"283\" y=\"-927.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ROOT</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-797.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2 (scientists)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M236.81,-870C216.99,-857.15 189.56,-839.35 167.74,-825.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.71,-822.3 159.42,-819.79 165.9,-828.17 169.71,-822.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.5\" y=\"-840.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-797.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">11 (lead)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;11 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263,-870.21C263,-858.8 263,-843.43 263,-830.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"266.5,-830.27 263,-820.27 259.5,-830.27 266.5,-830.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"283\" y=\"-840.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"341\" y=\"-797.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">27 (.)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;27 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.97,-870.06C293.81,-864.68 301.02,-858.44 307,-852 313.63,-844.86 319.92,-836.32 325.24,-828.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.17,-830.26 330.61,-819.95 322.28,-826.49 328.17,-830.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"335\" y=\"-840.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">punct</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1 (Many)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M88.75,-784.49C78.49,-779.4 68.17,-772.95 60,-765 53.37,-758.55 48.09,-750.04 44.07,-741.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.36,-740.65 40.11,-732.93 40.95,-743.49 47.36,-740.65\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4 (that)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;4 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>11&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.58,-783.26C219.83,-777.59 207.84,-771.13 197,-765 181.65,-756.32 164.96,-746.36 150.6,-737.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.72,-734.83 142.36,-732.61 149.07,-740.8 152.72,-734.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"211\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8 (research)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.95,-783.21C242.26,-771.1 230.37,-754.53 220.49,-740.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.58,-739.07 214.91,-732.99 217.9,-743.15 223.58,-739.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.5\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9 (may)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268.53,-783.21C272.37,-771.56 277.56,-755.8 281.99,-742.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285.2,-743.79 285.01,-733.2 278.55,-741.6 285.2,-743.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"289\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">aux</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"388\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">10 (eventually)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288,-783C306.82,-770.21 332.84,-752.51 353.62,-738.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.5,-741.34 361.8,-732.82 351.56,-735.55 355.5,-741.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"501\" y=\"-710.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">13 (therapies)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M295.37,-786.31C298.6,-785.12 301.85,-783.99 305,-783 338.93,-772.29 349.16,-775.98 383,-765 407.26,-757.13 433.45,-746.28 454.98,-736.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456.41,-739.9 464.09,-732.6 453.53,-733.52 456.41,-739.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"432.5\" y=\"-753.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obl</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-623.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5 (embryonic)</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"258\" y=\"-536.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6 (stem)</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"258\" y=\"-623.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7 (cell)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258,-609.21C258,-597.8 258,-582.43 258,-569.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.5,-569.27 258,-559.27 254.5,-569.27 261.5,-569.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-579.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>8&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.45,-696.02C190.67,-690.34 187.62,-683.93 185,-678 181.79,-670.73 178.5,-662.78 175.55,-655.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.85,-654.22 171.93,-646.2 172.33,-656.79 178.85,-654.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"201\" y=\"-666.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M213.06,-696.21C220.96,-684.22 231.75,-667.85 240.77,-654.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"243.55,-656.3 246.13,-646.02 237.7,-652.45 243.55,-656.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.5\" y=\"-666.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"469\" y=\"-623.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">12 (to)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M493.41,-696.02C490.95,-690.33 488.27,-683.93 486,-678 483.24,-670.81 480.46,-662.95 477.97,-655.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"481.31,-654.59 474.83,-646.22 474.67,-656.81 481.31,-654.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"498.5\" y=\"-666.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"549\" y=\"-623.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">17 (used)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;17 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.48,-696.21C517.19,-684.33 526.32,-668.17 534,-654.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.92,-656.5 538.79,-646.08 530.83,-653.06 536.92,-656.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"549.5\" y=\"-666.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-536.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">14 (that)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>17&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M514.78,-612.79C493.17,-604.29 468.5,-594.25 464,-591 454.73,-584.3 446.15,-575.22 439.13,-566.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"441.99,-564.61 433.09,-558.85 436.45,-568.89 441.99,-564.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"493.5\" y=\"-579.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">nsubj:pass</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"508\" y=\"-536.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">15 (could)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>17&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.9,-609.21C535.23,-597.45 527.53,-581.48 521,-567.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"524.24,-566.61 516.74,-559.12 517.93,-569.65 524.24,-566.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"541\" y=\"-579.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">aux</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"591\" y=\"-536.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">16 (be)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557.3,-609.21C563.11,-597.45 571,-581.48 577.68,-567.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"580.76,-569.63 582.05,-559.12 574.48,-566.53 580.76,-569.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"597.5\" y=\"-579.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">aux:pass</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"671\" y=\"-536.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">19 (treat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M583.24,-613.99C597.21,-608.21 613.09,-600.46 626,-591 635.27,-584.21 644.06,-575.25 651.38,-566.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"654.05,-569.05 657.72,-559.11 648.65,-564.59 654.05,-569.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"663\" y=\"-579.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">xcomp</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"636\" y=\"-449.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">18 (to)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M663.74,-522.3C661.26,-516.52 658.48,-509.99 656,-504 652.96,-496.66 649.73,-488.68 646.78,-481.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"650.07,-480.11 643.12,-472.11 643.57,-482.7 650.07,-480.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"670\" y=\"-492.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"726\" y=\"-449.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">20 (diseases)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>19&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M681.87,-522.21C689.63,-510.22 700.21,-493.85 709.07,-480.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"711.84,-482.33 714.33,-472.03 705.96,-478.52 711.84,-482.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-492.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obj</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"726\" y=\"-362.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">21 (that)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M726,-435.21C726,-423.8 726,-408.43 726,-395.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"729.5,-395.27 726,-385.27 722.5,-395.27 729.5,-395.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"747.5\" y=\"-405.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"726\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">22 (afflict)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;22 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>21&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M726,-348.21C726,-336.8 726,-321.43 726,-308.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"729.5,-308.27 726,-298.27 722.5,-308.27 729.5,-308.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-318.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"726\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">26 (Americans)</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;26 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>22&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M726,-261.21C726,-249.8 726,-234.43 726,-221.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"729.5,-221.27 726,-211.27 722.5,-221.27 729.5,-221.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"735.5\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obj</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"726\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">25 (million)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M726,-174.21C726,-162.8 726,-147.43 726,-134.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"729.5,-134.27 726,-124.27 722.5,-134.27 729.5,-134.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"751\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">nummod</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"671\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">23 (approximately)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"782\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">24 (128)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M715.13,-87.21C707.37,-75.22 696.79,-58.85 687.93,-45.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"691.04,-43.52 682.67,-37.03 685.16,-47.33 691.04,-43.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"725\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M739.04,-87.15C743.29,-81.47 747.96,-75.04 752,-69 756.95,-61.6 762.05,-53.37 766.6,-45.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"769.57,-47.62 771.64,-37.23 763.54,-44.06 769.57,-47.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x21ee0d5e460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graph image doesn't get saved, need to re-run the code\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09391d",
   "metadata": {},
   "source": [
    "### Attempt 3. Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267ec6e",
   "metadata": {},
   "source": [
    "<A HREF=\"https://stackoverflow.com/questions/64591644/how-to-get-height-of-dependency-tree-with-spacy\">Followed this code</A> couldn't have done it without this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c10ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'believe': 0, 'scientists': 1, 'Many': 2, 'lead': 1, 'that': 8, 'research': 2, 'embryonic': 3, 'cell': 3, 'stem': 4, 'may': 2, 'eventually': 2, 'to': 6, 'therapies': 3, 'used': 4, 'could': 5, 'be': 5, 'treat': 5, 'diseases': 6, 'afflict': 7, 'Americans': 8, 'million': 9, 'approximately': 10, '128': 10, '.': 1}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Try this just to the the height of the parse tree... using spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(sentence)\n",
    "depths = {}\n",
    "def walk_tree(node, depth):\n",
    "    depths[node.orth_] = depth\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return [walk_tree(child, depth+1) for child in node.children]\n",
    "[walk_tree(sent.root, 0) for sent in doc.sents]\n",
    "print(depths)\n",
    "print(max(depths.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3180a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    }
   ],
   "source": [
    "def walk_tree_depth(node, depth):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return max(walk_tree_depth(child, depth+1) for child in node.children )\n",
    "    else:\n",
    "        return depth\n",
    "    \n",
    "print([walk_tree_depth(sent.root, 0) for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff27b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[walk_tree_depth(sent.root, 0) for sent in doc.sents][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b9cac",
   "metadata": {},
   "source": [
    "#### This makes the actual depth dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5de79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of sentences and parse tree depth of each\n",
    "def walk_tree_depth(node, depth):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return max(walk_tree_depth(child, depth+1) for child in node.children )\n",
    "    else:\n",
    "        return depth\n",
    "    \n",
    "tree_depth = pd.DataFrame(columns = ['date', 'source', 'sentence', 'depth'])\n",
    "for i, speech in enumerate(text_df['sentences']):\n",
    "    for j, sentence in enumerate(speech):\n",
    "        doc = nlp(sentence)\n",
    "        depth = [walk_tree_depth(sent.root, 0) for sent in doc.sents][0]\n",
    "        tree_depth.loc[len(tree_depth)] = [text_df['date'].iloc[i], text_df['source'].iloc[i], sentence, depth]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dee528b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>To Chairman Dean and my great friend Dick Durb...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>Let me express my thanks to the historic slate...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>To President Clinton, who last night made the ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>I am grateful to finish this journey with one ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-06-03</td>\n",
       "      <td>gwb</td>\n",
       "      <td>To the love of my life, our next First Lady, M...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date source                                           sentence  depth\n",
       "0 2008-06-03    gwb  To Chairman Dean and my great friend Dick Durb...      6\n",
       "1 2008-06-03    gwb  Let me express my thanks to the historic slate...      9\n",
       "2 2008-06-03    gwb  To President Clinton, who last night made the ...      6\n",
       "3 2008-06-03    gwb  I am grateful to finish this journey with one ...      9\n",
       "4 2008-06-03    gwb  To the love of my life, our next First Lady, M...      6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_depth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46011c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6840, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7522b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_depth.to_csv('sentence_depth_gwb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d9651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
